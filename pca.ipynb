{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2cd055b-c7c6-4f94-a5e5-032df78f3c24",
   "metadata": {},
   "source": [
    "<font size=8>Dimensionality Reduction and Clustering</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e01fa-f9e0-4db1-b277-459eaf763cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "import matplotlib as mpl\n",
    "mpl.rc('axes', labelsize=16)\n",
    "mpl.rc('xtick', labelsize=14)\n",
    "mpl.rc('ytick', labelsize=14)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"11_Unsupervised\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"plots\", CHAPTER_ID)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "# import warnings\n",
    "# warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-stone",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-gospel",
   "metadata": {},
   "source": [
    "Working in high-dimensional spaces is often unconvenient or even impossible. One might want to reduce the dimensionality in order to:\n",
    "* Make visualizations\n",
    "* Save storage space of the data (compression)\n",
    "* Reduce computational costs of training algorithms, by reducing number of features.\n",
    "* Increase a models performance by increasing the signal/noise ratio, as well as the density of points (*curse of dimensionality*).\n",
    "\n",
    "The problem of reducing the dimensionality of features, while retaining most of the information, is called *dimensionality reduction* and there are two main approaches to it:\n",
    "* Projection: Project the high-dimensional space into a hyper-plane, collapsing all the features orthogonal to it.\n",
    "* Manifold-Learning: Learning the geometry of a lower-dimensional manifold, and projecting the data onto it.\n",
    "\n",
    "On the first category, the most known algorithm is Principal Component Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-diamond",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-solid",
   "metadata": {},
   "source": [
    "The aim of Principal Component Analysis is to find the direction onto which to project the data with minimum information loss.\n",
    "\n",
    "We will see this in action, but first, let's take a more intuitive, naive approach to the problem by looking at a toy example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a7be40-6431-434a-a555-6bbdd1c0074c",
   "metadata": {},
   "source": [
    "### Naive approach to dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405cfae1-f5ad-4eeb-9d06-a930e92c8bd4",
   "metadata": {},
   "source": [
    "We will create a ficticious dataset, $\\{x^{(i)}\\}$, of points in 2D, and suppose that for some reason we want to reduce the data to a single dimension. That is, each data instance $x^{(i)}$ is represented by two real number ($x^{(i)} \\in \\mathbb{R}^2$, in mathematical jargon), and we want to construct an approximate dataset in a one-dimensional space ($z^{(i)} \\in \\mathbb{R}$), i.e. each new instance ${z^{(i)}$ will be represented by a single number. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e764b-6c23-41d7-a521-6830099f2195",
   "metadata": {},
   "source": [
    "Of course, except in very specific situations (for example, $x_2 = 2 * x_1$) we will lose some information by doing this. The game consists in finding the way to choose this single number that reduces this information loss.\n",
    "\n",
    "Let's start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0920549a-1cfd-48dc-8dfa-81d20ad8a431",
   "metadata": {},
   "source": [
    "**Create a 2D dataset from an homogeneous normal distribution and rotate it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb83cb3-bacc-4306-95b0-e981dc476bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create independent random Gaussian data (200 points)\n",
    "m = 200\n",
    "np.random.seed(3)\n",
    "X_base = np.random.randn(m, 2) \n",
    "\n",
    "# Check dimension of resulting array (matrix)\n",
    "print(X_base.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ff08c-198c-48f1-854c-d8851b40a261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define angle by which to rotate and factor by which to stretch the data\n",
    "angle = np.pi / 8\n",
    "stretch = 5\n",
    "\n",
    "# Stretch matrix\n",
    "S = np.array([[stretch, 0],\n",
    "              [0, 1]])\n",
    "\n",
    "# Rotation matrix\n",
    "R = np.array([[np.cos(angle), np.sin(angle)], \n",
    "              [-np.sin(angle), np.cos(angle)]])\n",
    "\n",
    "# Stretch\n",
    "X = X_base @ S\n",
    "# Rotate\n",
    "X = X @ R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920ce30c-3188-4680-a02b-ca055126d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the resulting dataset \n",
    "ax = plt.figure(figsize=(8, 8)).add_subplot(111)\n",
    "ax.plot(*X.T, marker='x', color='k', ls='')\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel('$X_1$', fontsize=16)\n",
    "ax.set_ylabel('$X_2$', fontsize=16, rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2497e700-203f-40e3-a3ae-b7edb60ce4f9",
   "metadata": {},
   "source": [
    "Of course, these are just random numbers in 2D. Let us assume we have centred the data by removing the mean on each axis (that is why the data are centred at 0.0).\n",
    "\n",
    "You may think of a couple of examples of datasets when this situation may exist:\n",
    "\n",
    "* Height vs. Weight of a sample of people from a given population.\n",
    "* Price of some good vs. demand for that good.\n",
    "\n",
    "**Can you provide one or two additional examples?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-anxiety",
   "metadata": {},
   "source": [
    "One way to reduce the dimensionality of this dataset would be simply to **remove one of the dimensions**, but looking at the data it might make sense to **project on the diagonal directions**, and only keep one of them. There are two diagonals, so let's make the two projections and see which one works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_1 = X[:, 0] + X[:, 1] # x + y\n",
    "variant_2 = X[:, 0] - X[:, 1] # x - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ba83a-267d-459e-824d-c3cc810814e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the resulting dataset \n",
    "ax = plt.figure(figsize=(8, 8)).add_subplot(111)\n",
    "ax.plot(*X.T, marker='x', color='k', ls='')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "imin = np.argmin(X[:, 0])\n",
    "imax = np.argmax(X[:, 0])\n",
    "\n",
    "ax.plot([X[imin, 0], X[imax, 0]], [X[imin, 0], X[imax, 0]], ls=':', color='gray')\n",
    "ax.plot([X[imin, 0], X[imax, 0]], [-X[imin, 0], -X[imax, 0]], ls=':', color='gray')\n",
    "\n",
    "# Annotate new axes\n",
    "ax.annotate('$z_1$', [X[imax, 0], X[imax, 0]], fontsize=16)\n",
    "ax.annotate('$z_2$', [X[imax, 0], -X[imax, 0]], fontsize=16)\n",
    "\n",
    "# Uncomment these two lines to plot proyections\n",
    "# ax.plot(0.5*variant_1, 0.5*variant_1, 'x', color='orange', ls='')\n",
    "# ax.plot(0.5*variant_2, -0.5*variant_2, 'x', color='lightblue', ls='')\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel('$X_1$', fontsize=16)\n",
    "ax.set_ylabel('$X_2$', fontsize=16, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(10, 5)).add_subplot(111)\n",
    "\n",
    "ax.hist(variant_1, label='$z_1$', color='orange', bins=25)\n",
    "ax.hist(variant_2, label='$z_2$', color='lightblue', bins=25)\n",
    "ax.legend(loc=0, fontsize=17)\n",
    "\n",
    "ax.set_xlabel('$z$', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e8eb4-9d34-4138-bbc0-4774bda647ac",
   "metadata": {},
   "source": [
    "We see that there is one direction in which the data is more spread than the other one, and probably preserves more information. This would be a good candidate to choose $z$ from.\n",
    "\n",
    "**Which one of the two options would you choose?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b65e8a3-93ea-4e25-9dcb-39e4eba42cb2",
   "metadata": {},
   "source": [
    "However, the chosen direction is clearly **not the best**. \n",
    "\n",
    "**Can you draw the directions that you think would produce a better conservation of the data information? Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ec60dd-80ae-4611-94f7-e12148757c19",
   "metadata": {},
   "source": [
    "### Runnning PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-thinking",
   "metadata": {},
   "source": [
    "Actually, the main task of the PCA is to find the optimal set of axes onto which to project the available data. Each of the directions of these new axes are called Principal Components.\n",
    "\n",
    "In PCA, this is quantified by the variance of the data. Therefore, the first Principal Component is the direction that preserves most of the variance of the data. Further directions are found (as many as dimensions in the dataset --i.e. number of features), on the condition that each succesive component will retain as much remaining variance (information) as possible, and be orthogonal with all the previous ones.\n",
    "\n",
    "In other words, the algorithm fits an ellipsoid to the data, and then rotates the data axes so that they align with the ellipsoid's principal axes. The rotated axes are the principal components. For those of you who like linear algebra, this is equivalent to finding an orthogonal base in which the covariance matrix is diagonalised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbea698-cd25-4547-973e-7042689c7fbe",
   "metadata": {},
   "source": [
    "Let's see the implementation in `sklearn`.\n",
    "\n",
    "In this case, we are dealing with a `Transformer` class (not to be confused with the popular Deep Learning models). In `sklearn`, these classes have a `.fit` method, that takes a dataset as argument, and learns some parameters from it. In this case, it learns the covariance matrix from the data and how to invert it. They also have a `transform` method, that uses the learnt parameters to perform some transformation on the dataset. In this case convert the original dataset to the reduced set.\n",
    "\n",
    "Finally, the `fit_transform` method concatenates both steps.\n",
    "\n",
    "It is important for PCA that the dataset is normalised. We will then another transformer we have already seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Instatiate scaler and scale data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Find the principal components (how many components do we want?)\n",
    "pca = PCA(n_components=1)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39821134-8c89-4f28-a548-3682a61e0661",
   "metadata": {},
   "source": [
    "**Explore the shape of the output. Does it make sense?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559655b8-7e49-4450-83f6-4e7bdd5083e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, X_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-china",
   "metadata": {},
   "source": [
    "The coordinates of the axes chosen to project (i.e. the Principal Components) are stored in the `components_` attribute, row-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce7acba-e6b8-4acf-adb7-981760b7efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30124917-e979-437a-8c68-3ccafc39b224",
   "metadata": {},
   "source": [
    "**Let's see this directions in the plot above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b448a7-0f92-4174-8e9e-fca135ec7888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the resulting dataset \n",
    "ax = plt.figure(figsize=(8, 8)).add_subplot(111)\n",
    "ax.plot(*X_scaled.T, marker='x', color='k', ls='')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "z = pca.components_\n",
    "\n",
    "for i in range(len(z)):\n",
    "    #\n",
    "    # slope of direction\n",
    "    m = z[i, 0] / z[i, 1]\n",
    "    \n",
    "    # Plot line\n",
    "    ax.plot([X_scaled[imin, 0], X_scaled[imax, 0]], \n",
    "            [X_scaled[imin, 0] * m, X_scaled[imax, 0] * m], \n",
    "            ls=':', color='gray')\n",
    "    \n",
    "    # Plot arrow\n",
    "    size=1.0\n",
    "    ax.arrow(0, 0, z[i, 0]*size, z[i,1]*size, color='C{}'.format(i+1), width=0.05, head_width=0.1, alpha=0.8,\n",
    "             label='First PC')\n",
    "    \n",
    "    # Annotate new axes\n",
    "    ax.annotate('$z_{}$'.format(i+1), [X_scaled[imin, 0], X_scaled[imin, 0]*m], fontsize=16, color='C{}'.format(i+1))\n",
    "\n",
    "# Uncomment these lines to plot proyections onto the first PC (set zero on second component)\n",
    "# X_pca_cut = X_pca.copy()\n",
    "# X_pca_cut[:, 1] = 0\n",
    "# X_1 = pca.inverse_transform(X_pca_cut)\n",
    "# ax.plot(*X_1.T, 'x', color='orange', ls='')\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel('$X_1$', fontsize=16)\n",
    "ax.set_ylabel('$X_2$', fontsize=16, rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f53729-b076-44b4-a0fc-fa0496b96b50",
   "metadata": {
    "heading_collapsed": "true",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### A bit of algebra (Advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8995173c-f7e6-45a0-896e-3d18a49aceb6",
   "metadata": {},
   "source": [
    "Let's compute (numerically) the covariance matrix of the original (scaled) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-grant",
   "metadata": {},
   "source": [
    "Now, let's look at the covariance matrix of the transformed coordinates, this is what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the principal components (how many components do we want?)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(np.cov(X_pca.T).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-century",
   "metadata": {},
   "source": [
    "Note two things:\n",
    "1. the covariance matrix is now diagonal.\n",
    "2. that most of the variance is located in the first coordinate. (N.B.: PCA automatically orders the features by its variance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930087ca-95d1-4780-b4af-e37f41966834",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data in the transformed axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c63b3a-cfd1-4996-b456-9fc35fcd16e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In the transformed axis, the data look like an aligned elipsoid\n",
    "ax = plt.figure(figsize=(8, 8)).add_subplot(111)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot\n",
    "ax.plot(*X_pca.T, marker='x', color='k', ls='')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.axhline(0.0, color='gray', ls=':')\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel('$z_1$', fontsize=16)\n",
    "ax.set_ylabel('$z_2$', fontsize=16, rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43e0555-cf36-4332-a744-926216d02ec0",
   "metadata": {},
   "source": [
    "**Question**. Going back to the use examples from above (height vs. weight, ...), can you say what each new coordinate $z$ represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af71848c-a693-45d6-87a1-8756093517c4",
   "metadata": {},
   "source": [
    "We can easily go back to the original space using the `inverse_transform` method. **Complete the code below with the right input for this method**. Note that the code check if the reconstruction was done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c5d190-bca2-460a-b421-c17775c9ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reconstructed = pca.inverse_transform(X_pca)\n",
    "\n",
    "print('Is the reconstruction perfect? {}'.format('Yes' if np.allclose(X_scaled, X_reconstructed) else 'No'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4b75a5-55ec-46e3-a782-38e1c7de95f4",
   "metadata": {},
   "source": [
    "**Question**. Did we lose any information by going to the PCA space and back? Did we reduced the dimensionality of the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b425ceea-7788-4b6d-861f-678222fc328a",
   "metadata": {},
   "source": [
    "### Incomplete reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-grove",
   "metadata": {},
   "source": [
    "Going to the PCA space and back is not a reduction dimensionality task, and therefore does produce any information loss. Let's see what happens if we only keep the projection of the data onto the first principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA with a single component\n",
    "pca = PCA(n_components=1)\n",
    "X_pca_1D = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-danger",
   "metadata": {},
   "source": [
    "If we do the inverse transform, some information was lost, and so the inverted data is not the same as the original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reconstructed = pca.inverse_transform(X_pca_1D)\n",
    "print('Is the reconstruction perfect? {}'.format('Yes' if np.allclose(X_scaled, X_reconstructed) else 'No'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-valve",
   "metadata": {},
   "source": [
    "Let's take a look at this compressed data, and how it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(8, 8)).add_subplot(111)\n",
    "ax.plot(*X_scaled.T, marker='x', color='k', ls='', label='Original data')\n",
    "ax.plot(*X_reconstructed.T, marker='x', color='orange', ls='', label='Reconstructed')\n",
    "ax.legend(fontsize=16)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-place",
   "metadata": {},
   "source": [
    "This is exactly the projection on the direction given by the first principal component. In this way, the resulting compressed dataset retains the maximum possible variance. \n",
    "\n",
    "If we look at the covariance matrix, we see that not much was lost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original covariance matrix\\n', np.cov(X_scaled.T))\n",
    "print('\\nCompressed covariance matrix\\n', np.cov(X_reconstructed.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-reasoning",
   "metadata": {},
   "source": [
    "The fraction of the total variance (information) kept by each principal component is stored in the `explained variance_ratio_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe1d5a9-88df-485e-905b-7bc104202bd3",
   "metadata": {},
   "source": [
    "This shows that the projecting in the direction of the first PC retains over 92% of the data variance, while reducing the data dimension why half!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-asthma",
   "metadata": {
    "tags": []
   },
   "source": [
    "### An example in 4D (the Iris dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-loading",
   "metadata": {},
   "source": [
    "In order to reduce dimensionality, we can chose to keep the first `n` principal components of our data. This way, we make sure that we're throwing away the components that carry the least information (as measured by the variance).\n",
    "\n",
    "If we want to keep a fixed number of components, we can just set the `n_components` parameter of scikit-learn's `PCA` class. \n",
    "\n",
    "Let's use the Iris dataset. This famous dataset (it has its own [wikipedia page](https://en.wikipedia.org/wiki/Iris_flower_data_set)!) consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. Based on the combination of these four features, this dataset is used to learn to classify species. But here we will use it simply to show how PCA works in many dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "X, t = data['data'], data['target']\n",
    "names = data['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-proxy",
   "metadata": {},
   "source": [
    "Before transforming the data, lets plot every pair of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3)\n",
    "\n",
    "for ax,(i,j) in zip(axs.flatten(),[(0,1),(2,3),(0,2),(1,3),(0,3), (1,2)]):\n",
    "    ax.scatter(X[:,i], X[:,j],c=t,)\n",
    "    ax.set_xlabel(names[i])\n",
    "    ax.set_ylabel(names[j])\n",
    "    \n",
    "fig.set_size_inches(10,5)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-delta",
   "metadata": {},
   "source": [
    "Let's reduce our data to just two dimensions. **Complete the code below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=...)\n",
    "X2D = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, X2D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-aluminum",
   "metadata": {},
   "source": [
    "We can use the fact that we are only retaining two dimensions to plot the _entire_ tranformed dataset. **Note**: the colors are given by use, just to keep track of the Iris classes, but the PCA algorithm is completely agnostic to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*X2D.T, c=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-sweden",
   "metadata": {},
   "source": [
    "We see that now the data looks the most separated in the fist diretion, which keeps over 92% of the data variance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-reason",
   "metadata": {},
   "source": [
    "We can inverse the transformation, but as before, some information was lost in the projection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "X4D_inv = pca.inverse_transform(X2D)\n",
    "print('Is the reconstruction perfect? {}'.format('Yes' if np.allclose(X, X4D_inv) else 'No'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us plot the four features after reconstruction. Compare this with the first plot in this section.\n",
    "fig, axs = plt.subplots(2,3)\n",
    "\n",
    "for ax,(i,j) in zip(axs.flatten(),[(0,1),(2,3),(0,2),(1,3),(0,3), (1,2)]):\n",
    "    ax.scatter(X4D_inv[:,i], X4D_inv[:,j],c=t,)\n",
    "    ax.set_xlabel(names[i])\n",
    "    ax.set_ylabel(names[j])\n",
    "    \n",
    "fig.set_size_inches(10,5)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-indianapolis",
   "metadata": {},
   "source": [
    "A measure of how much is lost is the *reconstruction error*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.sum(np.square(X4D_inv - X), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0f22b4-1452-44ec-a001-f86695fff43d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Application on a high-dimensional dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1724eb2d-a1cb-4771-b6e4-f3e5b031b12c",
   "metadata": {},
   "source": [
    "Finding an optimal lower-dimensional representation of our data, allows us to store it using less space and reconstruct it loosing as little information as possible. Let's see how this works with images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa1f982-8305-4acf-9135-fb900dc392eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "mnist.target = mnist.target.astype(np.uint8)\n",
    "\n",
    "X_mnist = mnist[\"data\"]/255.0 # notice the normalisation\n",
    "t_mnist = mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1544d03b-887f-45ac-b689-c7cce470e51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(instances, images_per_row=5, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = plt.cm.binary, **options)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1818bb39-fb44-4992-b38e-7ae5b0050e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(X_mnist[:100], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d66ca-2c66-4a15-9caa-32f9c42c1861",
   "metadata": {},
   "source": [
    "Each digit consits on 784 pixels. Let's see how the reconstructed images when we use PCA to store it as a lower-dimensional vector.\n",
    "\n",
    "**Complete the code below with a resonable number for the number of components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97bd598-7b0a-4e7f-b34d-a7e9c30904aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=150)\n",
    "\n",
    "X_reduced = pca.fit_transform(X_mnist)\n",
    "X_recovered = pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85007c5c-fafe-404a-a61b-34f5f7afb327",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_mnist.shape, X_reduced.shape, X_recovered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8dd392-73d7-4c7b-9279-b639bdd55fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "plt.subplot(121)\n",
    "plot_digits(X_mnist[::2100])\n",
    "plt.title(\"Original\", fontsize=16)\n",
    "plt.subplot(122)\n",
    "plot_digits(np.abs(X_recovered[::2100]))\n",
    "plt.title(\"Compressed\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facfff3c-1ae1-4d9a-831a-e54ae30def2c",
   "metadata": {},
   "source": [
    "If we're not sure about what dimensionality should we impose, we can plot the cumulative sum of the explained variance ratio to see how much information is lost. If all features are used, it should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c13ff4-d8a3-45e6-baf8-ef80ffe54d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_mnist) #fit without reducing dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053b7cee-6cc5-4ba4-a062-21b4f81f2e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the first elements of the explaned variance\n",
    "print(pca.explained_variance_ratio_[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b6902-0e9a-48e8-8000-95b047dd86f2",
   "metadata": {},
   "source": [
    "**Question**. Compare and contrast with the cases above (Iris dataset and simulated set). What do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1392870-30a0-4517-916b-a304e3849e2c",
   "metadata": {},
   "source": [
    "It is interesting to see how many components we need to keep to preserve a given variance level. For example, 95%. To do this, we can compute the *cumulative sum* of the explained variance ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b53a17-746d-4a2a-8e03-588c9d111980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what fraction of the variance you wish to keep\n",
    "var_frac = 0.95\n",
    "\n",
    "# Compute the cumulative sum and plot it\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_) \n",
    "#this tells us how much information is retained if we stop at each dimension\n",
    "\n",
    "# At what moment does the cumulative zoom reach var_frac * 100 %?\n",
    "d = np.argmax(cumsum >= var_frac) + 1\n",
    "print('With {} dimensions, we preserve {} of the variance.'.format(d, var_frac))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(cumsum, linewidth=3)\n",
    "# plt.axis([0, 400, 0, 1])\n",
    "\n",
    "plt.axvline(d, color=\"k\", ls=\":\")\n",
    "plt.plot([0, d], [0.95, 0.95], \"k:\")\n",
    "plt.plot(d, 0.95, \"ko\")\n",
    "\n",
    "plt.xlabel(\"Dimensions\", fontsize=16)\n",
    "plt.ylabel(\"Explained Variance\", fontsize=16)\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c4808-601b-4b13-b486-4fbf2b020ffc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualizing PCs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d359e084-02f6-4e99-856e-4ea5a46e480f",
   "metadata": {},
   "source": [
    "Although the task we are dealing with here is dimensionality reduction, the directions given by the principal components can also be thought of as individual instances in the data space, therefore corresponding to one 28 x 28 pixel image each.\n",
    "\n",
    "One may wonder how do the first few PCs look like for this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cf24cc-2f20-4987-928f-a46b0582fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "npc = 100\n",
    "\n",
    "ncolumns = 10\n",
    "nrows = npc // ncolumns\n",
    "\n",
    "# Add extra row, if necessary\n",
    "if npc % ncolumns:\n",
    "    nrows += 1\n",
    "\n",
    "fig, axs = plt.subplots(nrows, ncolumns, figsize=(16, 2*nrows))\n",
    "\n",
    "for i, ax in zip(range(npc), axs.flatten()):\n",
    "    pci_reshaped = pca.components_[i].reshape(28,28)\n",
    "    ax.imshow(pci_reshaped, cmap='gray_r')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d2589-55a1-40b2-8c0a-44643b80aeb5",
   "metadata": {},
   "source": [
    "**Question.** Do you see anything worth mentioning from these figures?\n",
    "\n",
    "Note how the type of image change as we move from the first few PCs to the high-order ones. What do you think this means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd21483d-3a45-40af-8946-ee64e0092733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also plot the mean\n",
    "plt.imshow(pca.mean_.reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-exposure",
   "metadata": {
    "heading_collapsed": "true",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Kernel PCA (Advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-credit",
   "metadata": {},
   "source": [
    "A variant of PCA used to learn non-linear mappings is called *kernel-PCA*, which makes use of the *kernel trick* to map the original features into a higher-dimensional (maybe infinite-dimensional) space, in which PCA is applied. This is useful to learn more complex non-linear transformations.\n",
    "\n",
    "**Note**. Kernel methods are taught in the second course on **Advanced topics**. Please join us if you want to know how these techniques work.\n",
    "\n",
    "Kernel PCA has the **strong** disadvantage that the inverse transformation is not easy to obtain.\n",
    "We invite you to explore this algorithm and experiment with the different hyperparameters:\n",
    "\n",
    "* n_components\n",
    "* kernel. Choose what kernel is used to perform the mapping to a high dimensional space. You may try: {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘cosine’} \n",
    "* gamma. Length scale for 'rbf' kernel\n",
    "* degree. Polynomial degree for 'poly' kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d309fc-3bdf-4d8a-8d2e-9476de67fce3",
   "metadata": {},
   "source": [
    "### Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da70f2b0-c555-4756-a1a9-9cf568d77aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kpca = rbf_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(*X_kpca.T, c=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-aquatic",
   "metadata": {},
   "source": [
    "Looks funny, let's see how it behaves with a more complex dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f35f836-4a89-47c5-9da7-ad81ccb606ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Swiss Roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_swiss_roll\n",
    "\n",
    "X, z = make_swiss_roll(n_samples=1000, noise=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-canon",
   "metadata": {},
   "source": [
    "This dataset is a rolled plane, which is harder to decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 1], X[:, 2], c=z,  cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "ax = fig.add_subplot(211, projection='3d')\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=z, cmap=plt.cm.hot)\n",
    "ax.view_init(10, -70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-restaurant",
   "metadata": {},
   "source": [
    "Let's compare the results of different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_pca = KernelPCA(n_components = 2, kernel=\"linear\", fit_inverse_transform=True) #equivalent to PCA(n_components=2)\n",
    "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.0433, fit_inverse_transform=True)\n",
    "sig_pca = KernelPCA(n_components = 2, kernel=\"sigmoid\", gamma=0.001, coef0=1, fit_inverse_transform=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(11, 4))\n",
    "for subplot, pca, title in ((131, lin_pca, \"Linear kernel\"), \n",
    "                            (132, rbf_pca, \"RBF kernel, $\\gamma=0.04$\"), \n",
    "                            (133, sig_pca, \"Sigmoid kernel, $\\gamma=10^{-3}, r=1$\")):\n",
    "    X_reduced = pca.fit_transform(X)\n",
    "    if subplot == 132:\n",
    "        X_reduced_rbf = X_reduced\n",
    "    \n",
    "    plt.subplot(subplot)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=z, cmap=plt.cm.hot)\n",
    "    plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "    if subplot == 131:\n",
    "        plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-recommendation",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Manifold Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cbd619-0f20-46c6-b74c-6432a7079f7c",
   "metadata": {},
   "source": [
    "Manifold learning is used to discover non-linear patterns in the data. \n",
    "\n",
    "To explore this, we will use the Swiss roll data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b82c32a-93ed-448c-a256-cc88bf727291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_swiss_roll\n",
    "\n",
    "X_sr, z = make_swiss_roll(n_samples=1000, noise=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a54cd3-53b4-4126-85c6-37d800588e95",
   "metadata": {},
   "source": [
    "This dataset is a rolled plane, which is harder to decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef1b3bb-f140-4230-a27e-ff476e02ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "ax = fig.add_subplot(211, projection='3d')\n",
    "ax.scatter(X_sr[:, 0], X_sr[:, 1], X_sr[:, 2], c=z, cmap=plt.cm.hot)\n",
    "ax.view_init(10, -70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-composition",
   "metadata": {},
   "source": [
    "Of course, the optimal projection for the Swiss roll would be something that _unrolls_ the data, so that it looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(z, X_sr[:,1], c=z,  cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da93afdd-0403-4379-8871-fcff907230ee",
   "metadata": {},
   "source": [
    "Learning such kind of subspaces, which are embedded into a higher dimensional space, is called *Manifold Learning*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af355960-f77c-4c49-a844-b4984c67078e",
   "metadata": {},
   "source": [
    "### Local Linear Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa47ccc1-81d0-41b3-a32d-1b6e0d3c8fb8",
   "metadata": {},
   "source": [
    "A simple method, which we'll not cover in detail, is the *Locally Linear Embedding* (LLE). \n",
    "\n",
    "LLE works by fitting a hyperplane in `n_components` dimension to the `n_neighbors` points of each instance. Then, it projects the datapoints to these fitted subspaces. Let's see how it works on the Swiss roll.\n",
    "\n",
    "As always, we instantiate the object with some hyperparameters, and use the method `fit_transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10, random_state=42)\n",
    "X_reduced = lle.fit_transform(X_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2b8360-1be9-4b67-8e45-1d356202fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dimensions of what we found.\n",
    "print(X_sr.shape, X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.title(\"Unrolled swiss roll using LLE\", fontsize=14)\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=z, cmap=plt.cm.hot)\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.ylabel(\"$z_2$\", fontsize=18)\n",
    "# plt.axis([-0.065, 0.055, -0.1, 0.12])\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-agency",
   "metadata": {},
   "source": [
    "It is not bad, but not optimal either. \n",
    "\n",
    "**Task**. Experiment with the `n_neighbors` hyperparameter. Do you find better results? Dive into the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.LocallyLinearEmbedding.html#sklearn.manifold.LocallyLinearEmbedding) and see if you can find something else to tweak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bb29bd-2c3b-4b90-86b9-a37b705c2b3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### tSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1751c113-35d0-423e-b360-8d75fd992c02",
   "metadata": {},
   "source": [
    "A popular manifold learning technique used for visualizations is the *t-Distributed Stochastic Neighbor Embedding* or tSNE. This technique learns a non-linear mapping that tends to group similar instances toghether, while distancing disimilar instances appart,\n",
    "\n",
    "We will try it on the MNIST dataset. Notice how simply it is to use it, as always: instantiate, fit_transform, enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_reduced_tsne = tsne.fit_transform(X_mnist[:1000])#fit a subset to reduce computing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "scat = ax.scatter(*X_reduced_tsne.T, c=t_mnist[:1000], s=50, cmap='jet', \n",
    "                  edgecolors='None', alpha=0.8)\n",
    "fig.colorbar(scat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4ee181-3f0d-4d96-9827-1cb9fc94c0da",
   "metadata": {},
   "source": [
    "Look! The numbers have clustered in some cases, even if the algorithm is completely ignorant of the labels (which we have used to colour the points!). Amazing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0003f71d-37de-4962-975d-622d8aee04d1",
   "metadata": {},
   "source": [
    "Now let's try this in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2d9aed-6b78-478d-8c90-ab6315072299",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "X_reduced_tsne_3d = tsne.fit_transform(X_mnist[:1000])#fit a subset to reduce computing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3dcbfe-b30e-4844-811c-dc1fc1cb9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "scat = ax.scatter(*X_reduced_tsne_3d.T, c=t_mnist[:1000], s=10, cmap='jet', \n",
    "                  edgecolors='None', alpha=0.8)\n",
    "\n",
    "ax.set_xlim(-15, 15)\n",
    "ax.set_ylim(-15, 15)\n",
    "fig.colorbar(scat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f993998-ec05-4a5f-90ed-7722356275d1",
   "metadata": {},
   "source": [
    "**Let's discuss about this plot.** \n",
    "\n",
    "A script to obtain an interactive version is available in the repository.\n",
    "\n",
    "Usage:\n",
    "\n",
    "```\n",
    "python3 -i PATH-TO-REPO/scripts/tSNE_MNIST.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-intersection",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-smooth",
   "metadata": {},
   "source": [
    "The second most used unsupervised task, after Dimensionality Reduction, is probably clustering: The objective is to divide the dataset into a number of groups (*clusters*), with a rule to assign new instances a given *affinity* to each group. This is extremely useful in a number of settings:\n",
    "\n",
    "* For customer segmentation\n",
    "* For data analysis\n",
    "* As a dimensionality reduction technique\n",
    "* For anomaly detection (also called outlier detection)\n",
    "* For semi-supervised learning\n",
    "* For search engines\n",
    "* To segment an image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-reservation",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-australia",
   "metadata": {},
   "source": [
    "Let's introduce some mock data, which we'll try to cluster together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "blob_centers = np.array(\n",
    "    [[ 0.2,  2.3],\n",
    "     [-1.5 ,  2.3],\n",
    "     [-2.8,  1.8],\n",
    "     [-2.8,  2.8],\n",
    "     [-2.8,  1.3]])\n",
    "blob_std = np.array([0.4, 0.3, 0.1, 0.1, 0.1])\n",
    "\n",
    "\n",
    "X, y = make_blobs(n_samples=2000, centers=blob_centers,\n",
    "                  cluster_std=blob_std, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-bracelet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(X, y=None):\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=1)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-titanium",
   "metadata": {},
   "source": [
    "The K-means algorithm consists on:\n",
    "1. Pick random centroids of the clusters\n",
    "2. Label the data according to the closest centroid (the distance to each centroid plays the role of *affinity*)\n",
    "3. Compute new centroids as the mean position of all the instances having the same label\n",
    "4. Repeat steps 2 and 3 until the centroids position stop changing\n",
    "The algorithm is guaranteed to converge in a finite amount of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#the number of clusters has to be set beforehand\n",
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-train",
   "metadata": {},
   "source": [
    "The labels assigned to each training instance is stored in the attribute `label_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-fault",
   "metadata": {},
   "source": [
    "And assignation to labels of new samples is done through the `predict` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = kmeans.predict(X)\n",
    "\n",
    "(y_pred == kmeans.labels_).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-transport",
   "metadata": {},
   "source": [
    "Let's plot the regions, as well as the centroids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(X):\n",
    "    plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n",
    "\n",
    "def plot_centroids(centroids, weights=None, circle_color='w', cross_color='k'):\n",
    "    if weights is not None:\n",
    "        centroids = centroids[weights > weights.max() / 10]\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='o', s=35, linewidths=8,\n",
    "                color=circle_color, zorder=10, alpha=0.9)\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='x', s=2, linewidths=12,\n",
    "                color=cross_color, zorder=11, alpha=1)\n",
    "\n",
    "def plot_decision_boundaries(clusterer, X, resolution=1000, show_centroids=True,\n",
    "                             show_xlabels=True, show_ylabels=True):\n",
    "    mins = X.min(axis=0) - 0.1\n",
    "    maxs = X.max(axis=0) + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], resolution),\n",
    "                         np.linspace(mins[1], maxs[1], resolution))\n",
    "    Z = clusterer.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
    "                cmap=\"Pastel2\")\n",
    "    plt.contour(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),\n",
    "                linewidths=1, colors='k')\n",
    "    plot_data(X)\n",
    "    if show_centroids:\n",
    "        plot_centroids(clusterer.cluster_centers_)\n",
    "\n",
    "    if show_xlabels:\n",
    "        plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "    if show_ylabels:\n",
    "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    else:\n",
    "        plt.tick_params(labelleft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plot_decision_boundaries(kmeans, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-physiology",
   "metadata": {},
   "source": [
    "We can see how many iterations it took the algorithm to converge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-heart",
   "metadata": {},
   "source": [
    "Nevertheless is quite unstable, and depends on the random seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k, n_init=1, random_state=1)\n",
    "kmeans.fit(X)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_decision_boundaries(kmeans, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-domain",
   "metadata": {},
   "source": [
    "To surpass this, the algorithm runs on many different random seeds (setted by `n_init`), and uses the *best* final value, where *best* is measured as the *inertia*: The mean squared distance of each instance to its closest centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-store",
   "metadata": {},
   "source": [
    "We can compute (the negative of) the inertia on a given dataset, by using the `score` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.score(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-vaccine",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optimal number of clusters (advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-template",
   "metadata": {},
   "source": [
    "Similar to what we did in Dimensionality Reduction to find the number of principal components, one may ask what is the optimal number of clusters for a given dataset. One option is to choose look at the improvement as measured by the Inertia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_per_k = [KMeans(n_clusters=k, random_state=42).fit(X)\n",
    "                for k in range(1, 10)]\n",
    "inertias = [model.inertia_ for model in kmeans_per_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 10), inertias, \"bo-\")\n",
    "\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Inertia\", fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-ghost",
   "metadata": {},
   "source": [
    "We can see again a characteristic elbow, which might indicate that 4/5 could be a good number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundaries(kmeans_per_k[4-1], X)\n",
    "plt.title('k=4')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-victory",
   "metadata": {},
   "source": [
    "Another approach is to look at the *silhouette score*, which is the mean silhouette coefficient over all the instances. \n",
    "\n",
    "An instance's silhouette coefficient is equal to $(b - a)/\\max(a, b)$ where $a$ is the mean distance to the other instances in the same cluster (it is the mean intra-cluster distance), and $b$ is the mean nearest-cluster distance, that is the mean distance to the instances of the next closest cluster (defined as the one that minimizes $b$, excluding the instance's own cluster). \n",
    "\n",
    "The silhouette coefficient can vary between -1 and +1: a coefficient close to +1 means that the instance is well inside its own cluster and far from other clusters, while a coefficient close to 0 means that it is close to a cluster boundary, and finally a coefficient close to -1 means that the instance may have been assigned to the wrong cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-ballet",
   "metadata": {},
   "source": [
    "This score is implemented in the metrics module of scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_score(X, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-center",
   "metadata": {},
   "source": [
    "Let's use it to find the optimal number of clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "silhouette_scores = [silhouette_score(X, model.labels_)\n",
    "                     for model in kmeans_per_k[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(2, 10), silhouette_scores, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Silhouette score\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-donna",
   "metadata": {},
   "source": [
    "Effectively, 4 seems to be the optimal number of clusters for the dataset in question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c5d518-484b-41c7-ad2d-793aeba67e36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Play time! Eigenfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8fcff5-e6b2-44f5-b707-8ba0c9d9b1bb",
   "metadata": {},
   "source": [
    "We invite you to build a Face Recognizer using PCA:\n",
    "\n",
    "* Use PCA to project the dataset in the N principal components (try N=150 for example)\n",
    "* Plot the image corresponding to the first few (20? 30?) principal components (an *eigenface*)\n",
    "\n",
    "**BonusTrack**: Use K-means to cluster the data (in PCA-processed version). Plot different clusters to see if it manages to distinguish each person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af299e-d299-41f7-ba68-43fc210d5049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "from sklearn import datasets\n",
    "\n",
    "lfw_people = datasets.fetch_lfw_people(min_faces_per_person=70, resize=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871e0e63-faf6-46cc-8cdf-7d9f3bce5789",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lfw_people.data\n",
    "\n",
    "# Number of features\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# The label to predict is the id of the person\n",
    "t = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print('A dataset with {} instances of {} features and {} classes.'.format(len(X), n_features, n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58895b2b-8b2a-4d2a-9350-56b487553b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who are these people?\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa797d4-94c2-485b-bd4c-f80407337cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Is the dataset balanced?\n",
    "for i in range(len(target_names)):\n",
    "    print(target_names[i],':',sum(t == i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a46d96-b9c6-415f-9764-7ee9431fbace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets plot a few of examples\n",
    "n_pics_per_person = 6\n",
    "\n",
    "n_cols = n_pics_per_person\n",
    "n_rows = len(target_names)\n",
    "\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(1.6*n_cols, 2*n_rows))\n",
    "\n",
    "for i in range(len(target_names)):\n",
    "    # Select instances of that class\n",
    "    Xi = X[t == i]\n",
    "    # Randomly select n_pics_per_person\n",
    "    idj = np.random.choice(len(Xi), size=n_pics_per_person, replace=False)\n",
    "    \n",
    "    for j, jj in enumerate(idj):\n",
    "        axs[i, j].imshow(Xi[jj].reshape(50, 37), cmap='gray')\n",
    "        axs[i, j].axis('off')\n",
    "    axs[i, 0].set_title(target_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2cb10d-26bb-4150-883a-79b7589314e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, t, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df511fd-beae-4a02-8a73-fc5413715ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feec08c2-49de-4c32-ae38-cf17ae8da6c1",
   "metadata": {},
   "source": [
    "## Run PCA on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9990afa6-d2c3-48e7-b9b7-1b54532bfafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b33b9b6-3bc0-4aea-bc09-f8075eb46d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pca.components_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943dbdd2-e640-4241-8517-5d2fc0b05399",
   "metadata": {},
   "source": [
    "Note that here we have as many components as instances, not as features. If we don't specify, PCA takes the minimum between number of features and number of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b8b5a8-dd2b-4296-add5-9c26a7bb0ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d7f27c-4e41-4d33-bd96-b1c71275bd4b",
   "metadata": {},
   "source": [
    "Principal Components live in data space. They can therefore be visualised. Let us see the first few (more important) PCs, together with the data mean.\n",
    "Remember that each principal component lives in original space (i.e. 1850 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3501808-b3ba-4403-b1c0-654cbfe24fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eigenfaces = 100\n",
    "n_cols = 7\n",
    "\n",
    "n_rows = (n_eigenfaces + 1) // n_cols\n",
    "if (n_eigenfaces + 1) % n_cols:\n",
    "    n_rows += 1\n",
    "\n",
    "# Prepare grid of subplot\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(1.6*n_cols, 2*n_rows))\n",
    "\n",
    "# Remove axes for all\n",
    "for ax in axs.flatten():\n",
    "    ax.set_axis_off()\n",
    "\n",
    "# plot mean face\n",
    "_ = axs.flatten()[0].imshow(pca.mean_.reshape(50, 37), cmap='gray')\n",
    "_ = axs.flatten()[0].set_title('Mean')\n",
    "\n",
    "# plot eigenfaces\n",
    "for i, ax in zip(range(n_eigenfaces), axs.flatten()[1:]):\n",
    "    eigenface = pca.components_[i]\n",
    "    _ = ax.imshow(eigenface.reshape(50,37), cmap = plt.cm.gray)\n",
    "    _ = ax.set_title('PC{}'.format(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24884be5-c870-4055-bca6-2cf5e313e915",
   "metadata": {},
   "source": [
    "Now let us explore how much variance is explained? Let's see the first 10 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd2fbd-4113-4558-b5f5-e1f3ef03082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_[: 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eef161-b980-41bd-936f-4e6280c41769",
   "metadata": {},
   "source": [
    "Quite impressive! The first two PCs explain over 34% of the images variabilities. This is much better than the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c38cba5-4847-403b-a11d-32c6729e5427",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsum = np.cumsum(pca.explained_variance_ratio_) #this tells us how much information is retained if we stop at each dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da947f8c-d070-414c-ab05-43ef072c13fb",
   "metadata": {},
   "source": [
    "As above we can set a threhold of how much variance we want to retain, and use it to estimate the number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae8ef34-bb86-4065-a9da-a4e511c99757",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.argmax(cumsum >= 0.95) + 1\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4688d1-a680-4fac-bd14-9aa25af21e73",
   "metadata": {},
   "source": [
    "With 135 dimensions, we preserve 95% of the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0799c1f1-f5b2-479d-a9ea-87685f81dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(cumsum, linewidth=3)\n",
    "plt.axis([0, 400, 0, 1])\n",
    "\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "\n",
    "plt.plot([d, d], [0, 0.95], \"k:\")\n",
    "plt.plot([0, d], [0.95, 0.95], \"k:\")\n",
    "plt.plot(d, 0.95, \"ko\")\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd81c631-623a-4b8a-ac3b-f462571d20f4",
   "metadata": {},
   "source": [
    "## Reconstructing me softly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aab8e8-b248-4687-87ad-91503a5b686d",
   "metadata": {},
   "source": [
    "It is interesting to see how an image is recovered progressively as we add more and more PCs to the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29abfe35-dba7-49fc-98d0-b17f8bc4f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 45\n",
    "plt.imshow(X_train[idx].reshape(50, 37), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59a4ce-3605-441e-8eae-f62ddd13f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us compute the coefficients for this specific image\n",
    "coef = pca.transform([X_train[idx],])\n",
    "print(coef.shape, pca.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ddef18-d8ed-4da3-8120-82068a48ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute elements corresponding to each PC\n",
    "partial = coef.T * pca.components_ \n",
    "\n",
    "# Build cumulative reconstructions\n",
    "cpartial = np.cumsum(partial, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4b9950-8611-4a23-9221-5d85b5e53c79",
   "metadata": {},
   "source": [
    "Each element in `cpartial` then has the reconstruction with an increasing number of PCs (except for the mean).\n",
    "\n",
    "Let's see this at work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e818521-eab4-4176-a976-798e6f309e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of PCs to use in reconstruction\n",
    "max_summed_elements = 350\n",
    "\n",
    "# Thin factor, plot one reconstruction every `thin`\n",
    "thin = 20\n",
    "\n",
    "# Plotting definitions (n_columns, n_rows, etc)\n",
    "n_images = max_summed_elements // thin + 2 # sum two for mean and original\n",
    "n_cols = 7\n",
    "\n",
    "n_rows = n_images // n_cols\n",
    "if n_images % n_cols:\n",
    "    n_rows += 1\n",
    "\n",
    "# Prepare grid of subplot\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(1.6*n_cols, 2*n_rows))\n",
    "for ax in axs.flatten():\n",
    "    ax.set_axis_off()\n",
    "\n",
    "# plot eigenfaces\n",
    "for i, ax in zip(range(n_images), axs.flatten()):\n",
    "    if i == 0:\n",
    "        # Plot mean as first reconstruction\n",
    "        reconstruction = pca.mean_.reshape(50, 37)\n",
    "    else:    \n",
    "        reconstruction = cpartial[i*thin]\n",
    "    ax.imshow(reconstruction.reshape(50,37) + pca.mean_.reshape(50, 37), cmap = plt.cm.gray)\n",
    "    ax.set_title('{} PCs'.format(i*thin))\n",
    "\n",
    "axs.flatten()[i+1].imshow(X_train[idx].reshape(50, 37), cmap='gray')\n",
    "axs.flatten()[i+1].set_title('Original')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77b2c93-20e3-44f1-8f74-ba5694f666ec",
   "metadata": {},
   "source": [
    "In agreement with what we saw above, most of the information of the original image is recovered using ~140 PCs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee94f79-d681-457a-9f7a-fc185763f6af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Beyond the lectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbe6382-6366-466b-a81b-8e4dfb4e6237",
   "metadata": {},
   "source": [
    "In this section, we present a few advanced topics, some of which you may want to come back to after we have seen classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b469cf9-5368-427c-9feb-0fa54b7eaca0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Application: Clustering for Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7ae004-d9d1-4a70-906f-705eb6a5eba2",
   "metadata": {},
   "source": [
    "Clustering can be used as a preprocessing step for supervised training.\n",
    "\n",
    "Here, we explore this application on the digits dataset, the small brother of the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7aad45-c467-43e5-862d-91ce3f4fc8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_digits, t_digits = load_digits(return_X_y=True)\n",
    "X_train, X_test, t_train, t_test = train_test_split(X_digits, t_digits, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9257101-7bf5-4057-96d3-37b4752a68b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what we have\n",
    "print('Labels:', np.unique(t_digits))\n",
    "print('Size of datasets (train; test):', X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c1a199-26f1-42e5-84ab-1f54330b0a06",
   "metadata": {},
   "source": [
    "Let's fit a LogisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b65f4-1415-4081-b152-a3f9cb403ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e2f3f2-c990-48d7-afc7-aeba6b65a954",
   "metadata": {},
   "source": [
    "The accuracy on the test set is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb67b10-80c2-40b9-92c5-e00852d2821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_score = log_reg.score(X_test, t_test)\n",
    "log_reg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d39e4be-d37a-4dec-a745-303648e02c7e",
   "metadata": {},
   "source": [
    "Now let's use a K-means algorithm as a pre-processing pipeline.\n",
    "\n",
    "This means that instead of using the full dataset of size `X_train.shape`, we will used the transformed version, with a reduced number of features, corresponding to the distance to each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984a4a6c-fe89-4cbf-b761-2401cddbfd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want 50 clusters\n",
    "pp_Kmeans = KMeans(n_clusters=50, random_state=42)\n",
    "\n",
    "X_reduced_KM = pp_Kmeans.fit_transform(X_train)\n",
    "\n",
    "print(X_train.shape, X_reduced_KM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5c7473-fda5-4ab2-8ff5-fa403bfe8060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"kmeans\", pp_Kmeans),\n",
    "    (\"log_reg\", LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)),\n",
    "])\n",
    "pipeline.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dcb467-57d1-49a7-9f51-1312b89c024b",
   "metadata": {},
   "source": [
    "And compute the test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb20170-de20-47b4-b615-f66f84aa4d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_score = pipeline.score(X_test, t_test)\n",
    "pipeline_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2055d0-d954-448e-975d-fffffe95ead9",
   "metadata": {},
   "source": [
    "We see that the error rate on the test set dropped by a factor of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f210aaac-7208-4e30-9f8b-8f25ffb11521",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (1-pipeline_score)/(1-log_reg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb327c62-14a7-4ab8-9c43-3c1c393f7b73",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Application: Clustering for Semi-Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3dc5bf-3d28-4bf1-935f-cd4bedd2e148",
   "metadata": {},
   "source": [
    "Imagine the situation in which you don't any labels, so you decide to label by hand a few of them. Let's do this with the digits dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307c509d-879f-43d2-a912-e7dfde4d53c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_digits, t_digits = load_digits(return_X_y=True)\n",
    "X_train, X_test, t_train, t_test = train_test_split(X_digits, t_digits, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f93025-f4b4-47b3-909e-1068af448b11",
   "metadata": {},
   "source": [
    "We choose the first 50 (random choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0be86e-113d-4082-90fd-2c154e218d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labeled = 50\n",
    "\n",
    "X_representative_digits = X_train[:n_labeled]\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "for index, X_representative_digit in enumerate(X_representative_digits):\n",
    "    plt.subplot(n_labeled // 10, 10, index + 1)\n",
    "    plt.imshow(X_representative_digit.reshape(8, 8), cmap=\"binary\", interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b36465-deb5-4768-98b2-f31584980367",
   "metadata": {},
   "source": [
    "and label them by hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763da623-5a30-4dd9-a6ca-bd702c731f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_representative_digits = t_train[:n_labeled]\n",
    "t_representative_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c67e8-8f44-49ce-b440-eac57b071abf",
   "metadata": {},
   "source": [
    "And now we use this to train our dataset. Let's fit and see the performance of our model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc90042-2b3d-46d8-bb22-b8d9a402947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", random_state=42)\n",
    "log_reg.fit(X_representative_digits, t_representative_digits)\n",
    "log_reg.score(X_test, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f49ac5a-9de4-42c1-9439-521f0284900e",
   "metadata": {},
   "source": [
    "The accuracy is pretty low, but is reasonable given that we're training in only 50 instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1e432c-e486-4f0f-8cbd-1e269927e20c",
   "metadata": {},
   "source": [
    "One way we can improve this is by picking better digits to label. If we pick good representatives of our data, our model will have more information to learn from. \n",
    "\n",
    "We can do this by clustering our digits, and picking one representative from each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b48bbe-d9bb-4167-90b2-f09055dee875",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "X_digits_dist = kmeans.fit_transform(X_train)\n",
    "\n",
    "# Keep instance closer to each cluster centrer\n",
    "representative_digit_idx = np.argmin(X_digits_dist, axis=0)\n",
    "X_representative_digits = X_train[representative_digit_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a11361-d9df-4335-8f1d-59f148f475f0",
   "metadata": {},
   "source": [
    "Now, we didn't pick representative digits at random, but we picked the ones closer to each clusters centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076a233-f285-42d4-8ecc-5bc3ee7e2fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "for index, X_representative_digit in enumerate(X_representative_digits):\n",
    "    plt.subplot(k // 10, 10, index + 1)\n",
    "    plt.imshow(X_representative_digit.reshape(8, 8), cmap=\"binary\", interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e98c51-629d-4e79-8db9-a4cc06a2a974",
   "metadata": {},
   "source": [
    "We can proceed and label these 50 by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b769a96-5801-4ea7-b19e-1c3785a5512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_representative_digits = t_train[representative_digit_idx]\n",
    "t_representative_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b432688-edea-4d9a-a693-5cf5bc479518",
   "metadata": {},
   "source": [
    "And train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38c1e7-b5a6-4cd4-9203-87c6106b165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg.fit(X_representative_digits, t_representative_digits)\n",
    "log_reg.score(X_test, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf0691f-1af7-427c-a66d-48cccaaea681",
   "metadata": {},
   "source": [
    "The accuracy on the test set is much better! And we're still training on only 50 instances, the difference is that we picked correctly the representatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6273372-2045-49f1-bfbd-db702cb6f08e",
   "metadata": {},
   "source": [
    "But we can use our clustering algorithm to go even further. Let's replicate the label of each representative to the rest of the instances of that cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd3eaa-25a2-4187-9c4e-63fc42b908dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty vector of the right shape\n",
    "t_train_propagated = np.empty(len(X_train), dtype=np.int32)\n",
    "\n",
    "#lets iterate over the clusters\n",
    "for i in range(k):\n",
    "    #the predicted cluster for each instance in the training set is saved in kmeans.labels_\n",
    "    t_train_propagated[kmeans.labels_==i] = t_representative_digits[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa3c2e4-4990-45e5-a001-d28060bb8007",
   "metadata": {},
   "source": [
    "And now, let's train with this new automatically labelled **full** dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745f1d17-ee8c-49b7-9efb-8d2f1c6911c1",
   "metadata": {},
   "source": [
    "<img width=600px src=\"https://media.giphy.com/media/xUA7ba9aksCuKR9dgA/giphy.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc526967-69c9-48f3-9c03-bf60a3ec014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg.fit(X_train, t_train_propagated)\n",
    "log_reg.score(X_test, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df0ebee-23ea-4c5c-a2b2-e52d872ff834",
   "metadata": {},
   "source": [
    "The score got even better! This technique is called semi-supervised learning: An unsupervised learning technique is used to propagate labels on the training set, which is used as input for a supervised model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d82348-5656-4690-9ea3-708ee84bcac6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train a SVC on the reduced faces dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c690b3b-5c5a-451c-bdc0-922023886e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "from sklearn import datasets\n",
    "lfw_people = datasets.fetch_lfw_people(min_faces_per_person=70, resize=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b756ba78-b529-40ce-94bb-a54f5eb76c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature matrix (X)\n",
    "X = lfw_people.data\n",
    "\n",
    "# Number of features\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# The label to predict (t) is the id of the person (a number from 0 to 6)\n",
    "t = lfw_people.target\n",
    "\n",
    "# In case you want to match this with the actual name of the person, \n",
    "# the information comes packed in the `target_names` atrribute\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print('A dataset with {} instances of {} features and {} classes.'.format(len(X), n_features, n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b84a14-0ed5-4d57-946b-0c70f1a3ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who are these people?\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6256eefb-be18-4e87-8101-bd9cb41eef40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Is the dataset balanced?\n",
    "for i in range(len(target_names)):\n",
    "    print(target_names[i],':',sum(t == i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d5dcb0-dd7e-4fa0-ac23-109c331dd016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets plot a few of examples\n",
    "n_pics_per_person = 6\n",
    "\n",
    "n_cols = n_pics_per_person\n",
    "n_rows = len(target_names)\n",
    "\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(1.6*n_cols, 2*n_rows))\n",
    "\n",
    "for i in range(len(target_names)):\n",
    "    # Select instances of that class\n",
    "    Xi = X[t == i]\n",
    "    # Randomly select n_pics_per_person\n",
    "    idj = np.random.choice(len(Xi), size=n_pics_per_person, replace=False)\n",
    "    \n",
    "    for j, jj in enumerate(idj):\n",
    "        axs[i, j].imshow(Xi[jj].reshape(50, 37), cmap='gray')\n",
    "        axs[i, j].axis('off')\n",
    "    axs[i, 0].set_title(target_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f115ea3-1baa-440d-b34d-5422ce5a594b",
   "metadata": {},
   "source": [
    "**Complete the following cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfecf3c-5ba3-434e-8567-e285e47e936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, t_train, t_test = train_test_split(...)\n",
    "\n",
    "# Let's see the shape of the resulting training set\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e489a3-2055-4272-a231-338d286dc20d",
   "metadata": {},
   "source": [
    "**Train a SVC on a dataset with reduced dimensionality**\n",
    "\n",
    "* Complete the following code.\n",
    "* What criterion would you use to choose `d` (see notebook above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff8477f-3cc7-4f9c-a877-c9634fcc2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a SVC with and without dimensionality reduction.\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "d = ...\n",
    "\n",
    "# Instantiate a pipeline including the PCA step\n",
    "pipe = make_pipeline(PCA(n_components=d), SVC())\n",
    "# and a SVC _without_ dimensionality reduction\n",
    "svc =  SVC()\n",
    "\n",
    "# Train both algorithms\n",
    "svc.fit(..., ...)\n",
    "pipe.fit(..., ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2d2730-3da7-43d5-93bb-aef964fc201e",
   "metadata": {},
   "source": [
    "**Compare the score of both predictors**\n",
    "\n",
    "* Use the test set.\n",
    "* What conclusion can you reach? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814a8a1c-93ad-46a7-a1b9-56f563eb65d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.score(..., ...), svc.score(..., ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd460b6-3c27-4c5f-8d44-77706cec654b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Other algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd4a580-416d-49d6-b827-b80067de790f",
   "metadata": {},
   "source": [
    "There are many methods for Dimensionality Reduction and Clustering. PCA and K-Means are by far the most populars ones, but there are many others. \n",
    "\n",
    "Try other algorithms on the datasets presented in this notebook. \n",
    "\n",
    "Additional **dimensionality reduction** algorithms implemented in scikit-learn are:\n",
    "\n",
    "* Random projections (implmented in the [sklearn.random_projection](https://scikit-learn.org/stable/modules/classes.html?highlight=sklearn%20random#module-sklearn.random_projection) module).\n",
    "\n",
    "* Isomaps ([sklearn.manifold.Isomap](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.Isomap.html)).\n",
    "\n",
    "* MultiDimensional Scaling (MDS; [sklearn.manifold.MDS](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.MDS.html)).\n",
    "\n",
    "There is also a vast set of **clustering** algorithms implemented in the [clustering](https://scikit-learn.org/stable/modules/clustering.html) module.\n",
    "\n",
    "![Comparison of Algorithms](https://scikit-learn.org/stable/_images/sphx_glr_plot_cluster_comparison_001.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc9f83-b14f-4350-90b4-0c8fff36b161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
